{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Macroeconomics Assignment 5\n",
    "Paula Beck\n",
    "\n",
    "handed in: 29.01.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some preparation\n",
    "\n",
    "# import packages\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "# set path\n",
    "wd = Path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: download data and save\n",
    "downloaded on 17.01.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     date  Median one-year ahead expected inflation rate  \\\n",
      "0  201306                                       3.090884   \n",
      "1  201307                                       3.162522   \n",
      "2  201308                                       3.395071   \n",
      "3  201309                                       3.367290   \n",
      "4  201310                                       3.174733   \n",
      "\n",
      "   Median three-year ahead expected inflation rate  \n",
      "0                                         3.416846  \n",
      "1                                         3.310545  \n",
      "2                                         3.799491  \n",
      "3                                         3.546918  \n",
      "4                                         3.196597  \n"
     ]
    }
   ],
   "source": [
    "# load consumer expectation data\n",
    "\n",
    "# instead of changing the excel file manually, I load the specific data directly in python by loading the explicite sheet and skipping the first three rows. Also, I only load the first three columns as those are the one we need.\n",
    "exp = pd.read_excel(wd/'data'/'FRBNY-SCE-Data.xlsx', sheet_name = 'Inflation expectations', skiprows=3, usecols=[0,1,2])\n",
    "\n",
    "exp.rename(columns={'Unnamed: 0':'date'}, inplace=True)\n",
    "\n",
    "print(exp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  inflation\n",
      "0  1960-01-01   1.034483\n",
      "1  1960-02-01   1.730104\n",
      "2  1960-03-01   1.730104\n",
      "3  1960-04-01   1.724138\n",
      "4  1960-05-01   1.724138\n"
     ]
    }
   ],
   "source": [
    "# load inflation data\n",
    "\n",
    "inf = pd.read_csv(wd/'data'/'CPALTT01USM659N.csv', sep = ',', decimal ='.', names=['date', 'inflation'], header=0)\n",
    "\n",
    "print(inf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: convert to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---data types of inflation data------------\n",
      "date          object\n",
      "inflation    float64\n",
      "dtype: object\n",
      "---data types of expectation data----------\n",
      "date                                                 int64\n",
      "Median one-year ahead expected inflation rate      float64\n",
      "Median three-year ahead expected inflation rate    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# first look what data types they have\n",
    "print('---data types of inflation data------------')\n",
    "print(inf.dtypes)\n",
    "print('---data types of expectation data----------')\n",
    "print(exp.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date column of inflation dataframe to datetime\n",
    "inf.date  = pd.to_datetime(inf.date)\n",
    "# set frequency to montly\n",
    "inf.date = pd.PeriodIndex(inf.date, freq='m')\n",
    "\n",
    "# convert the date column of the expectation dataframe to a string and add '01', then convert to datetime\n",
    "exp.date = exp.date.astype('str') + '01'\n",
    "exp.date = pd.to_datetime(exp.date, format = '%Y%m%d')\n",
    "# set frequency to montly\n",
    "exp.date = pd.PeriodIndex(exp.date, freq='m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date as index\n",
    "inf = inf.set_index('date')\n",
    "exp = exp.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.rename(columns={exp.columns[0]:'med1y',exp.columns[1]:'med3y'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge expectation data to inflation dataframe based on the index\n",
    "# inner merge such that only those rows remain that are not NA for both data sources\n",
    "df = inf.merge(exp, on='date', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: calculate forecast errors and forecast revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### check again !!!!!\n",
    "\n",
    "df['med1y_shift'] = df['med1y'].shift(1)\n",
    "df['med3y_shift'] = df['med3y'].shift(3)\n",
    "\n",
    "df['ferror'] = df.inflation - df.med1y_shift\n",
    "df['frevision'] = df.med1y_shift - df.med3y_shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: drop all columns except from forecast errors and forecast revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ferror', 'frevision']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: remove NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ferror</th>\n",
       "      <th>frevision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-09</th>\n",
       "      <td>-2.210146</td>\n",
       "      <td>-0.021775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10</th>\n",
       "      <td>-2.403677</td>\n",
       "      <td>0.056744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11</th>\n",
       "      <td>-1.937660</td>\n",
       "      <td>-0.624758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12</th>\n",
       "      <td>-1.694861</td>\n",
       "      <td>-0.350321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01</th>\n",
       "      <td>-1.558893</td>\n",
       "      <td>-0.058756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ferror  frevision\n",
       "date                        \n",
       "2013-09 -2.210146  -0.021775\n",
       "2013-10 -2.403677   0.056744\n",
       "2013-11 -1.937660  -0.624758\n",
       "2013-12 -1.694861  -0.350321\n",
       "2014-01 -1.558893  -0.058756"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: estimate equation (1)\n",
    "\n",
    "- equation: ferror = constant + frevision + error\n",
    "- set cov_type = 'HAC'\n",
    "- set cov_kwds = {'maxlags':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>ferror</td>      <th>  R-squared:         </th> <td>   0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   23.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>5.56e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:50:23</td>     <th>  Log-Likelihood:    </th> <td> -126.59</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    98</td>      <th>  AIC:               </th> <td>   257.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    96</td>      <th>  BIC:               </th> <td>   262.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HAC</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -1.1840</td> <td>    0.160</td> <td>   -7.423</td> <td> 0.000</td> <td>   -1.497</td> <td>   -0.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frevision</th> <td>    1.0989</td> <td>    0.228</td> <td>    4.812</td> <td> 0.000</td> <td>    0.651</td> <td>    1.547</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.044</td> <th>  Durbin-Watson:     </th> <td>   0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.593</td> <th>  Jarque-Bera (JB):  </th> <td>   1.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.223</td> <th>  Prob(JB):          </th> <td>   0.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.717</td> <th>  Cond. No.          </th> <td>    2.64</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 3 lags and without small sample correction"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 ferror   R-squared:                       0.183\n",
       "Model:                            OLS   Adj. R-squared:                  0.174\n",
       "Method:                 Least Squares   F-statistic:                     23.15\n",
       "Date:                Mon, 17 Jan 2022   Prob (F-statistic):           5.56e-06\n",
       "Time:                        15:50:23   Log-Likelihood:                -126.59\n",
       "No. Observations:                  98   AIC:                             257.2\n",
       "Df Residuals:                      96   BIC:                             262.4\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:                  HAC                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -1.1840      0.160     -7.423      0.000      -1.497      -0.871\n",
       "frevision      1.0989      0.228      4.812      0.000       0.651       1.547\n",
       "==============================================================================\n",
       "Omnibus:                        1.044   Durbin-Watson:                   0.291\n",
       "Prob(Omnibus):                  0.593   Jarque-Bera (JB):                1.136\n",
       "Skew:                          -0.223   Prob(JB):                        0.567\n",
       "Kurtosis:                       2.717   Cond. No.                         2.64\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 3 lags and without small sample correction\n",
       "\"\"\""
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols(formula='ferror ~ frevision', data=df)\n",
    "fit = model.fit(cov_type = 'HAC', cov_kwds = {'maxlags':3})\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Interpretation"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98f8afcc7b498ff748bcf3669bc6fa2980d8228748497c4de9780cb8988f727b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('compMacro': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
